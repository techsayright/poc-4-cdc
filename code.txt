docker-compose up -d

## Loading data into Postgres

docker run -it --rm --network=poc-4-cdc_default \
         -v "$PWD":/home/config/Data \
         debezium/postgres:11 psql -h postgres -U postgres

Password = postgres

At the command line:

```
CREATE DATABASE students;
\connect students;
```

Load our admission data table:

```
CREATE TABLE admission
(student_id INTEGER, gre INTEGER, toefl INTEGER, cpga DOUBLE PRECISION, admit_chance DOUBLE PRECISION,
CONSTRAINT student_id_pk PRIMARY KEY (student_id));

\copy admission FROM '/home/config/Data/admit_1.csv' DELIMITER ',' CSV HEADER;
```

insert into admission values ( 12345, 98, 98, 0.09,0.87);
update admission set gre = 99 where student_id = 12345;
delete from admission where student_id = 12345;


Load the research data table with:

```
CREATE TABLE research
(student_id INTEGER, rating INTEGER, research INTEGER,
PRIMARY KEY (student_id));

\copy research FROM '/home/config/Data/research_1.csv' DELIMITER ',' CSV HEADER;
```


##if you want to create topic manually

docker-compose exec broker kafka-topics --create \
    --bootstrap-server localhost:9092 \
    --partitions 1 \
    --replication-factor 1 \
    --topic psg-admission


## Connect Postgres database as a source to Kafka
```
curl -X POST -H "Accept:application/json" -H "Content-Type: application/json" \
      --data @postgres-source.json http://localhost:8083/connectors
```


for showing connectors and its status
```
curl -H "Accept:application/json" localhost:8083/connectors/

curl localhost:8083/connectors/s3-connector/status
```
##for showing logs of connections if err exist or not
docker logs -f connect


The two tables in the `students` database will now show up as topics in Kafka.
You can check this by entering the Kafka container:

```
docker exec -it <kafka-container-id> /bin/bash
```

and listing the available topics:

```
/usr/bin/kafka-topics --list --zookeeper zookeeper:2181
```

```
/usr/bin/kafka-console-consumer --bootstrap-server localhost:9092 --topic test --from-beginning

```


## Create tables in KSQL

Bring up a KSQL server command line client as a container:

```
docker-compose exec ksqldb-cli ksql http://ksqldb-server:8088 

                          or

docker run --network postgres-kafka-demo_default \
           --interactive --tty --rm \
           confluentinc/cp-ksql-cli:latest \
           http://ksql-server:8088
```

To see your updates, a few settings need to be configured by first running:

```
set 'commit.interval.ms'='2000';
set 'cache.max.bytes.buffering'='10000000';
set 'auto.offset.reset'='earliest';
```

### Mirror Postgres tables

The Postgres table topics will be visible in KSQL, and we will create
KSQL streams to auto update KSQL tables mirroring the Postgres tables:

```
SHOW TOPICS;

print 'topic' from beginning;

CREATE STREAM admission_src (student_id INTEGER, gre INTEGER, toefl INTEGER, cpga DOUBLE, admit_chance DOUBLE)\
WITH (KAFKA_TOPIC='dbserver1.public.admission', VALUE_FORMAT='AVRO');

#create stream courses_src (course_id INTEGER, course_name STRING) WITH (KAFKA_TOPIC='demo.mydb.courses', VALUE_FORMAT='AVRO');

select * from admission_src emit changes;


##for table joining reason we have to partition data by student_id

CREATE STREAM admission_src_rekey WITH (PARTITIONS=1) AS \
SELECT * FROM admission_src PARTITION BY student_id;

SHOW STREAMS;

##it will also create new table nd topic named ADMISSION_SRC_REKEY

CREATE TABLE admission (student_id INTEGER PRIMARY KEY, gre INTEGER, toefl INTEGER, cpga DOUBLE, admit_chance DOUBLE)\
WITH (KAFKA_TOPIC='ADMISSION_SRC_REKEY', VALUE_FORMAT='AVRO');

SHOW TABLES;

CREATE STREAM research_src (student_id INTEGER, rating INTEGER, research INTEGER)\
WITH (KAFKA_TOPIC='local.students.research', VALUE_FORMAT='AVRO');

CREATE STREAM research_src_rekey WITH (PARTITIONS=1) AS \
SELECT * FROM research_src PARTITION BY student_id;

CREATE TABLE research (student_id INTEGER PRIMARY KEY, rating INTEGER, research INTEGER)\
WITH (KAFKA_TOPIC='RESEARCH_SRC_REKEY', VALUE_FORMAT='AVRO');
```

Currently KSQL uses uppercase casing convention for stream, table, and field
names.

### Create downstream tables

We will create a new KSQL streaming table to join students' chance of
admission with research experience.

```
CREATE TABLE research_boost AS \
  SELECT a.student_id as student_id, \
         a.admit_chance as admit_chance, \
         r.research as research \
  FROM admission a \
  LEFT JOIN research r on a.student_id = r.student_id;
```

and another table calculating the average chance of admission for
students with and without research experience:

```
CREATE TABLE research_ave_boost WITH (KAFKA_TOPIC='research_ave_boost', VALUE_FORMAT='AVRO') AS SELECT research, SUM(admit_chance)/COUNT(admit_chance) as ave_chance FROM research_boost GROUP BY research;


```

## Add a connector to sink a KSQL table to s3
note: s3 bucket should be created before run below command
```
curl -X POST -H "Accept:application/json" -H "Content-Type: application/json" \
--data @custom-connectors/connectors/s3-sink.json http://localhost:8083/connectors
```

## Update the source Postgres tables and watch the s3 bucket update



##for MongoDB------------

docker-compose exec mongo1 /usr/bin/mongo --eval 'rs.initiate({_id : "rs0",members:[{ _id : 0, host : "mongo1:27017", priority: 1.0 },{ _id : 1, host : "mongo2:27017", priority: 0.5 }]})'

docker exec -it mongo1 bash

#to start mongo
mongo

use class
db.student.insert([
{ _id : 105, first_name : 'Bob', last_name : 'Hopper' }
]);

db.student.find().pretty()



SELECT courses.course_name, \
    subjects.subject_name, \
    chapters.chapter_name, \
    subchapters.subchapter_name \
FROM courses \
LEFT JOIN subjects ON courses.course_id = subjects.course_id
LEFT JOIN chapters ON subjects.subject_id = chapters.subject_id
LEFT JOIN subchapters ON chapters.chapter_id = subchapters.chapter_id emit changes;



CREATE stream class_boost AS \
    SELECT c.course_name as course_name, \
        s.subject_name as subject_name, \
        ch.chapter_name as chapter_name, \
        sc.subchapter_name as subchapter_name \
    FROM courses c\
    LEFT JOIN subjects s ON c.course_id = s.subject_id
    LEFT JOIN chapters ch ON s.subject_id = ch.chapter_id
    LEFT JOIN subchapters sc ON ch.chapter_id = sc.subchapter_id emit changes;


CREATE TABLE course_sub AS SELECT courses.course_name,subjects.subject_name FROM courses LEFT JOIN subjects ON courses.course_id = subjects.course_id;


  SELECT a.student_id as student_id, \
         a.admit_chance as admit_chance, \
         r.research as research \
  FROM admission a \
  LEFT JOIN research r on a.student_id = r.student_id;


  CREATE stream course_sub AS SELECT c.course_name,s.subject_name FROM courses c left JOIN subjects s on c.course_id = s.subject_id;

----------------
  CREATE table course_sub AS SELECT courses.course_id as course_id, course_name, subjects.course_id as subject_id, subject_name FROM courses INNER JOIN subjects ON courses.course_id = subjects.subject_id;

  CREATE table chap_sub AS SELECT chapters.chapter_id as chapter_id, chapter_name, subject_id, subchapters.chapter_id as subchapter_id, subchapter_name  FROM chapters INNER JOIN subchapters ON chapters.chapter_id = subchapters.subchapter_id;

  CREATE table class_boost AS SELECT course_id, course_name, chap_sub.subject_id as subject_id, subject_name, chapter_id, chapter_name, subchapter_id, subchapter_name FROM course_sub INNER JOIN chap_sub ON course_sub.course_id = chap_sub.chapter_id;

select *, rowtime from subchapters_src emit changes;


CREATE TABLE course_sub AS SELECT courses.course_id as course_id, course_name, subjects.course_id as subject_id, subject_name FROM courses INNER JOIN subjects ON courses.course_id = subjects.subject_id;

CREATE OR REPLACE STREAM course_sub WITH (
    kafka_topic = 'subchapters_src_new',
    VALUE_FORMAT='AVRO'
)   AS
    SELECT *, rowtime AS time FROM subchapters_src
    EMIT CHANGES;

CREATE OR REPLACE STREAM class_boost WITH (
    kafka_topic = 'CLASS_BOOST',
    VALUE_FORMAT='AVRO'
)   AS 
    SELECT c.course_name as course_name, \
        s.subject_name as subject_name, \
        ch.chapter_name as chapter_name, \
        sc.subchapter_name as subchapter_name \
    FROM courses_src_new c\
    LEFT JOIN subjects_src_new s ON c.course_id = s.subject_id
    LEFT JOIN chapters_src_new ch ON s.subject_id = ch.chapter_id
    LEFT JOIN subchapters_src_new sc ON ch.chapter_id = sc.subchapter_id emit changes;